---
title: "Unifi Controller in Fedora/CentOS/RHEL"
date: 2024-09-12T14:39:37+02:00
type: "post"
tags:
- linux
- fedora
---

This article contains instructions how to reliable run Unify Controller from Ubiquity via podman found in Fedora, CentOS, RHEL, clones or pretty much any Linux distribution. I tested this on Fedora 40 running with SELinux in enforcing mode and rootless containers.

First off, create a pod with few exposed ports, this is the minimum required ports for the controller to operate, feel free to add optional ports if you like. Do not expose MongoDB port for security reasons.

    podman pod create --name=unifi -p 8443:8443 -p 8080:8080 -p 3478:3478/udp -p 10001:10001/udp

Create a podman volume for MongoDB database.

    podman volume create unifi-db

Start MongoDB 5.0 and keep in mind that this article was written for controller version 8.4 which required MongoDB 5.0. Different version might require different MongoDB version.

    podman run -d --pod unifi --name unifi-db -e MONGO_INITDB_ROOT_USERNAME=root -e MONGO_INITDB_ROOT_PASSWORD=unifi -v unifi-db:/data/db:Z docker.io/mongo:5.0

Run the following command to create a user for the controller:

    podman run --rm -it --pod unifi --name unifi-init --entrypoint=/usr/bin/mongosh docker.io/mongo:5.0 --authenticationDatabase admin --host unifi-db -u root -p unifi admin --eval "db.createUser({user: 'unifi', pwd: 'unifi', roles: [{role: 'dbOwner', db: 'unifi'},{role: 'dbOwner', db: 'unifi_stat'}]});"

You do not need to change usernames or passwords as MongoDB container is only accessible internally (from the pod). Create another volume for the controller:

    podman volume create unifi-app

And start the controller from an image maintained by LinuxServer.io since Ubiquity does not provide any official images at this time:

    podman run -d --pod unifi --name unifi-app -e PUID=1000 -e PGID=1000 -e TZ=Europe/Prague -e MONGO_USER=unifi -e MONGO_PASS=unifi -e MONGO_HOST=unifi-db -e MONGO_PORT=27017 -e MONGO_DBNAME=unifi -e MONGO_AUTHSOURCE=admin -v unifi-app:/config:Z lscr.io/linuxserver/unifi-network-application:latest

Visit your host URL `https://podman-host:8443` and perform initial setup or restore from backup. Then, stop and delete both containers. All the data are kept in the two volumes created above, do not worry you will loose any configuration data.

    podman stop unifi-app
    podman stop unifi-db
    podman rm unifi-app
    podman rm unifi-db

Generate new quadlet systemd units, note the deprecation warning by podman - this command may be removed in the future therefore systemd units need to be generated by a new command which is still work in progress at the time of writing:

    cd $HOME/.config/systemd/user/
    podman generate systemd --new --files --name unifi
    systemctl enable --now --user pod-unifi.service

Check systemd user unit `pod-unifi` where you will find the overall status and logs. Keep in mind that all the data are kept in your `$HOME/.local/share/containers/storage/volumes/` directory, this includes automatic backups done by the controller. I suggest to do configuration-only backups regularly. To find the exact location of your data:

    podman volume inspect unifi-app
    ...
    /home/lzap/.local/share/containers/storage/volumes/unifi-app/_data
    ...

On my system, I need to backup the following directory: `/home/lzap/.local/share/containers/storage/volumes/unifi-app/_data/data/backup/`. You can do the same for the MongoDB data stored in the volume named `unifi-db`, but I *think* that only statistics are stored there - nothing important for a home deployment. Tho, if you are running a public service, you may be legally obligated to store records of client data.

Alternatively, you can just skip all of instructions above and only create the two volumes and create the following systemd units which were generated for me:

```
# pod-unifi.service

[Unit]
Description=Podman pod-unifi.service
Documentation=man:podman-generate-systemd(1)
Wants=network-online.target
After=network-online.target
RequiresMountsFor=/run/user/1001/containers
Wants=container-unifi-app.service container-unifi-db.service
Before=container-unifi-app.service container-unifi-db.service

[Service]
Environment=PODMAN_SYSTEMD_UNIT=%n
Restart=on-failure
TimeoutStopSec=70
ExecStartPre=/usr/bin/podman pod create \
	--infra-conmon-pidfile %t/pod-unifi.pid \
	--pod-id-file %t/pod-unifi.pod-id \
	--exit-policy=stop \
	--name=unifi \
	-p 8443:8443 \
	-p 8080:8080 \
	-p 3478:3478/udp \
	-p 10001:10001/udp \
	--replace
ExecStart=/usr/bin/podman pod start \
	--pod-id-file %t/pod-unifi.pod-id
ExecStop=/usr/bin/podman pod stop \
	--ignore \
	--pod-id-file %t/pod-unifi.pod-id  \
	-t 10
ExecStopPost=/usr/bin/podman pod rm \
	--ignore \
	-f \
	--pod-id-file %t/pod-unifi.pod-id
PIDFile=%t/pod-unifi.pid
Type=forking

[Install]
WantedBy=default.target
```

```
# container-unifi-db.service

[Unit]
Description=Podman container-unifi-db.service
Documentation=man:podman-generate-systemd(1)
Wants=network-online.target
After=network-online.target
RequiresMountsFor=%t/containers
BindsTo=pod-unifi.service
After=pod-unifi.service

[Service]
Environment=PODMAN_SYSTEMD_UNIT=%n
Restart=on-failure
TimeoutStopSec=70
ExecStart=/usr/bin/podman run \
	--cidfile=%t/%n.ctr-id \
	--cgroups=no-conmon \
	--rm \
	--pod-id-file %t/pod-unifi.pod-id \
	--sdnotify=conmon \
	--replace \
	-d \
	--name unifi-db \
	-e MONGO_INITDB_ROOT_USERNAME=root \
	-e MONGO_INITDB_ROOT_PASSWORD=unifi \
	-v unifi-db:/data/db:Z docker.io/mongo:5.0
ExecStop=/usr/bin/podman stop \
	--ignore -t 10 \
	--cidfile=%t/%n.ctr-id
ExecStopPost=/usr/bin/podman rm \
	-f \
	--ignore -t 10 \
	--cidfile=%t/%n.ctr-id
Type=notify
NotifyAccess=all

[Install]
WantedBy=default.target
```

```
# container-unifi-app.service

[Unit]
Description=Podman container-unifi-app.service
Documentation=man:podman-generate-systemd(1)
Wants=network-online.target
After=network-online.target
RequiresMountsFor=%t/containers
BindsTo=pod-unifi.service
After=pod-unifi.service

[Service]
Environment=PODMAN_SYSTEMD_UNIT=%n
Restart=on-failure
TimeoutStopSec=70
ExecStart=/usr/bin/podman run \
	--cidfile=%t/%n.ctr-id \
	--cgroups=no-conmon \
	--rm \
	--pod-id-file %t/pod-unifi.pod-id \
	--sdnotify=conmon \
	--replace \
	-d \
	--name unifi-app \
	-e PUID=1000 \
	-e PGID=1000 \
	-e TZ=Europe/Prague \
	-e MONGO_USER=unifi \
	-e MONGO_PASS=unifi \
	-e MONGO_HOST=unifi-db \
	-e MONGO_PORT=27017 \
	-e MONGO_DBNAME=unifi \
	-e MONGO_AUTHSOURCE=admin \
	-v unifi-app:/config:Z lscr.io/linuxserver/unifi-network-application:latest
ExecStop=/usr/bin/podman stop \
	--ignore -t 10 \
	--cidfile=%t/%n.ctr-id
ExecStopPost=/usr/bin/podman rm \
	-f \
	--ignore -t 10 \
	--cidfile=%t/%n.ctr-id
Type=notify
NotifyAccess=all

[Install]
WantedBy=default.target
```

Note my UID on the host system, it is 1001 you might need to change that to your own (typically 1000).

If this article helped, share it on your favourite social networks. Cheers!
